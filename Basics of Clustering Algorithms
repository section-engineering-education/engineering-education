# Basics of Cluster Algorithms

When presented with large amounts of data for analysis, it becomes increasingly complex to be able to determine how to analyze large scatters of data. The process of testing every single data point as valid to a group will prove to be tedious and time-consuming, especially when there are hundreds of points to test. Thankfully, that’s where clustering algorithms come in to help. Taking a process that could have taken hundreds of man-hours and reducing it to short computing time. Clustering is the act of gathering data points and assorting these points into sectors based on similarities, or in the computing case proximity. Depending on the structure of the data it may optimal to choose one type of cluster algorithm [https://www.kdnuggets.com/2019/10/right-clustering-algorithm.html#:~:text=The%20centers%20of%20clusters%20should,the%20dataset%20and%20every%20cluster.] over another; doing this may reduce the processing time or increase the accuracy. To help narrow down the right type for the job the basic cluster algorithms will be covered.  

## Basic types of Clustering Algorithms

### Centroid based

This type of algorithm identifies the clusters of data according to the closeness of the data points. The algorithm determines the optimum local point of these cluster points and does an iterative method of calculations for processing. Something note of this note is this requires prior knowledge of the number of clusters in the data set. For example, in the infographic below it would be stated there are three known sets of clusters in the data set and separate these accordingly.
![](https://drive.google.com/file/d/1rjfbLUzpBhtL-G_Eeb3gxtmAfbhdvvIh/view?usp=sharing)
One of the best examples of this algorithm is known as K-means. Where “k” is defined as the total number of determined center points. Some of the benefits of K-means is that it is easily implemented, has relatively quick processing speed, scalable, consistently converges, and easily adapts to new data sets. Some of the caveats of this simplicity may be that it does not handle outliers well, requires a manual k value, may produce varying results from the same information, and trouble identifying clusters of varying size and density and identifying values that are in multiple dimensions.  K-means may be used in areas where there is linear information, such as determining test scores or the probability of having heart attacks.

### Connectivity based

Like the connectivity algorithm, this model is based on the Euclidean distance of data points. It classifies the data points close in proximity have more similarity than data points that are wildly spaced apart. Connectivity can be broken down into 2 different approaches: top-down and bottom-up.

The bottom-up method treats every data point as a single cluster and merges each cluster from the increasing distance till all the points are contained within a single cluster; much like mitosis performed in reverse. Top-down approaches use the same method in reverse, where all data points start as a single cluster and divided into independent clusters varying on the subjective distance of the points. These algometric methods are typically visualized through a hierarchical dendrogram chart much like the infographic below.  
![](https://drive.google.com/file/d/1BoTMCw4htlMt6U27tp7MmcluK4hZRiDe/view?usp=sharing)
One of the main examples of this algorithm is known as hierarchal clustering. Unlike K-means, hierarchical does not require prior knowledge of the total number of cluster points and is not linear, rather it is quadratic. Given that it has increased complexity it also requires more processing power and offers low efficiency. That being said, it will have reproducible results, can work in multiple dimensions, is not sensitive to the distance metric, and has the unique feature of being able to recover parts of the hierarchy. This type of algorithm can be useful areas such as identifying different classes of plants and animals through similarities in DNA, predicting the stock market, or even determining different classes of cells.
 
